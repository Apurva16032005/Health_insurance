{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc65c958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ Generating synthetic data...\n",
      "ðŸ§  Training the Random Forest model...\n",
      "\n",
      "--- Model Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1021\n",
      "         1.0       1.00      1.00      1.00       979\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "âœ… SUCCESS! Model saved to: d:\\Desktop\\insurance-claim-checker\\backend\\backend\\models\\ml_model.pkl\n",
      "ðŸš€ Now restart your backend terminal to use this new brain.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. GENERATE SYNTHETIC DATA\n",
    "# We are simulating 5000 bills to teach the AI what fraud looks like.\n",
    "print(\"âš¡ Generating synthetic data...\")\n",
    "np.random.seed(42)\n",
    "n_samples = 5000\n",
    "\n",
    "# --- Genuine Bills (Safe) ---\n",
    "# Low tampering score, normal amounts, lots of medical words\n",
    "gen_cnn = np.random.uniform(0.0, 0.3, n_samples)\n",
    "gen_meta = np.random.choice([0, 1], n_samples, p=[0.95, 0.05])\n",
    "gen_amt = np.random.normal(1.0, 0.05, n_samples)\n",
    "gen_nlp = np.random.randint(5, 15, n_samples)\n",
    "genuine_data = np.column_stack((gen_cnn, gen_meta, gen_amt, gen_nlp))\n",
    "genuine_labels = np.zeros(n_samples) # Label 0 = Real\n",
    "\n",
    "# --- Fraud Bills (Fake) ---\n",
    "# High tampering score, amount mismatch, few medical words\n",
    "fake_cnn = np.random.uniform(0.6, 1.0, n_samples)\n",
    "fake_meta = np.random.choice([0, 1], n_samples, p=[0.4, 0.6])\n",
    "fake_amt = np.random.uniform(1.5, 5.0, n_samples)\n",
    "fake_nlp = np.random.randint(0, 5, n_samples)\n",
    "fake_data = np.column_stack((fake_cnn, fake_meta, fake_amt, fake_nlp))\n",
    "fake_labels = np.ones(n_samples) # Label 1 = Fraud\n",
    "\n",
    "# Combine them\n",
    "X = np.vstack((genuine_data, fake_data))\n",
    "y = np.hstack((genuine_labels, fake_labels))\n",
    "\n",
    "# 2. TRAIN THE MODEL\n",
    "print(\"ðŸ§  Training the Random Forest model...\")\n",
    "# Split into Training (80%) and Testing (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Scale the numbers so the AI understands them better\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# The AI Brain\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 3. TEST THE RESULTS\n",
    "print(\"\\n--- Model Report ---\")\n",
    "preds = model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "# 4. SAVE THE MODEL\n",
    "# We need to save this to the 'backend/models' folder\n",
    "current_dir = os.getcwd()\n",
    "# If we are in 'notebooks' folder, go up one level, then into backend/models\n",
    "save_path = os.path.abspath(os.path.join(current_dir, \"..\", \"backend\", \"models\", \"ml_model.pkl\"))\n",
    "\n",
    "# Fix for VS Code execution path variations\n",
    "if \"backend\" not in save_path:\n",
    "     save_path = os.path.join(current_dir, \"backend\", \"models\", \"ml_model.pkl\")\n",
    "\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "with open(save_path, \"wb\") as f:\n",
    "    pickle.dump({'model': model, 'scaler': scaler}, f)\n",
    "    \n",
    "print(f\"âœ… SUCCESS! Model saved to: {save_path}\")\n",
    "print(\"ðŸš€ Now restart your backend terminal to use this new brain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc9c5c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\apurva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\apurva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\apurva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: seaborn in c:\\users\\apurva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\apurva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\apurva\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\apurva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\apurva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\apurva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\apurva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\apurva\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\apurva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\apurva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\apurva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\apurva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\apurva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\apurva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\apurva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\apurva\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee130fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
